---
layout: post
subclass: post
title: "운영체제 (4) CPU Scheduling"
date: 2018-09-17 00:00:04
tags: [dudaji, computer-science, operating_system]
excerpt: "운영체제 CPU Scheduling에 대한 정리입니다."
disqus: True
---

## CPU 스케줄링이란?

CPU 스케줄링 : 여러 개의 프로세스가 실행 준비상태일 때 시스템 내 CPU는 그 중 하나를
선택해 실행하는 결정을 내려야 하는데 그것이 CPU 스케줄링이다.

CPU 스케줄링의 가정)

- CPU는 하나이고 그래서 한 번에 하나의 프로세스만 처리 가능한 것으로 가정한다.
- 시분할(time sharing) 환경인 것으로 가정한다.

CPU 스케줄링의 중요한 목표는 CPU 이용률을 높이는 것이다. 예를 들어 하나의 프로세스가 I/O 작업이 필요한 상황이라면 대기하면 안 된다. 하나의 프로세스만 메모리에 load된 것이 아니기 때문에 다른 프로세스에 CPU의 사용을 양도하는 것이 CPU 이용률을 높이는데 적절하다고 할 수 있다.

위의 상황처럼 특정 상황에서 CPU를 어떤 프로세스에 할당할 것인가를 결정하는 것이
CPU 스케줄링이다.

CPU 스케줄링을 할 때는 중요하게 고려해야 하는 부분이 있다. 바로
'CPU-I/O 버스트 사이클'이다.

## CPU - I/O 버스트 사이클

Process의 실행을 잘 살펴보면 CPU burst와 I/O burst로 나누어진다.

- CPU burst : 사용자 프로그램이 CPU를 직접 가지고 빠른 명령을 수행하는 상태
- I/O burst : I/O 요청이 발생해 커널에 의해 입출력 작업을 진행하는 상태(비교적 느림)

중요한 것은 프로세스마다 CPU burst와 I/O burst의 비율이 다르다는 것이다. 이것이 CPU 스케줄링의 이유다.
프로세스는 I/O bound process와 CPU bound process로 나누어진다.

- I/O bound process : I/O 중심의 프로세스로 I/O 요청이 빈번하고 CPU burst는 짧다.
- CPU bound process : I/O 작업을 거의 수행하지 않고 CPU burst가 길게 나타낸다.

![CPU_burst_distribution](/images/operating_system/CPU_burst_distribution.png)

CPU burst의 분포를 살펴보면 대개 CPU burst가 짧게 나타나는 것을 알 수 있다. 시분할 시스템 환경에서는 사용자에 대한 빠른 응답이 중요하기 때문에 CPU burst가 짧은 프로세스에 우선적으로 CPU를 할당하는 스케줄링이 필요하다. 또, 이 때의 이점은 I/O 장치의 이용률도 높아진다는 것이다. 이유는 CPU를 잠시 사용하고 바로 I/O 작업을 수행할 수 있기 때문이다.

중요한 것은 위의 CPU burst 분포를 고려하여 상황에 적절한 CPU 스케줄링 알고리즘을 선택하는 것이 필요하다는 것이다.

이 CPU 스케줄링를 실제로 수행하는 것은 'CPU 스케줄러'다.

## CPU 스케줄러

CPU 스케줄러 : 준비상태에 있는 프로세스들 중에서 어떠한 프로세스에게 CPU를 할당할 것인지를 결정하는 운영체제의 코드
(short-term scheduler라고도 한다.)

이 CPU 스케줄러가 역할을 하는 상황은 크게 4가지라고 볼 수 있다.

1. Process가 실행 중이다가 I/O 요청 등으로 blocked 상태로 전환될 때
2. Timer 인터럽트가 발생하여 running에서 ready로 프로세스 상태가 전환될 때
3. Process가 I/O 작업을 완료하고 인터럽트를 발생시키고 ready 상태롤 전환될 때
4. Process가 실행 중이다가 수행을 완료해서 종료될 때

위 4가지 상황에서 (1), (4) 상황은 선택의 여지가 없다. Ready Queue에 하나라도 프로세스가 있다면 선택을 해야 한다. 반면, (2), (3) 상황은 선택의 여지가 있다.

상황 (1), (4) 과 같은 상황을 '비선점 방식'이라고 한다.
CPU를 획득한 프로세스가 스스로 CPU를 반납하기 전에는 CPU를 점유하는 방식이다.

상황 (2), (3) 과 같은 상황은 '선점형 방식'이라고 한다.
CPU 점유를 원하는 프로세스가 있어도 강제로 빼앗아 다른 Process에 CPU를 할당하는 방식을 말한다.

이 중 선점형 방식의 경우 고려해야 할 상황이 있다.
'공유자료에 대한 접근'과 '커널(시스템) 자료에 대한 접근'이다. 이유는 '데이터 일관성' 때문이다.

이렇게 프로세를 선택하고 나면 선택된 프로세스에 CPU를 할당하는 작업이 필요한데 이 때 역할을 하는 것이 '디스패처(Dispatcher)'이다.

## 디스패처(Dispatcher)

디스패처 : 새롭게 선택된 프로세스가 CPU를 할당받고 작업을 수행할 수 있도록 환경설정을 하는 커널 모듈

디스패처가 수행하는 작업을 살펴보면

1. 현재 수행 중이던 프로세스의 문맥(Context)를 그 프로세스의 PCB에 저장한다.
2. 새롭게 선택된 프로세스의 문맥을 PCB로부터 복원한다.
3. CPU의 제어권을 넘긴다.
4. 사용자 모드로 시스템의 상태를 전환한다. 이릍 통해 사용자 프로그램에 CPU 제어권이 넘어간다.
5. 사용자 프로그램은 복원된 문맥 중 PC에 있는 수행주소를 읽어서 수행한다.

위 과정에서 소요되는 시간을 모두 '디스패처 지연(dispatch latency)'이라고 한다.
(문맥교환의 오버헤드도 디스패처 지연에 포함되는 것이다.)

그럼 이제 실제 스케줄링을 수행해야 하는데 방법은 다양할 수 있다. 그러므로 상황에 알맞는 스케줄링 알고리즘을 선택해야 하는데 이를 위해서는 '지표'를 통해 특성을 비교할 필요가 있다. 이 때 필요한 것이 '스케줄링 기준'이다.

## 스케줄링 기준(Scheduling Criteria)

지표를 하나씩 살펴보면,

CPU 이용률 : 전체 시간 중 CPU가 명령을 수행한 시간의 비율

( CPU가 명령을 수행한 시간 / 전체시간 )

부하가 적은 시스템의 경우 40%, 부하가 큰 시스템의 경우 90% 정도의 CPU 이용률을 보인다. 시스템 전체 성능과 굉장히 밀접한 지표이고 CPU의 휴면 상태를 최대한 줄이는 것이 굉장히 중요하기 때문에 상당히 중요한 지표라고 할 수 있다.

처리량(throughput) : 주어진 시간동안 CPU burst를 완료한 프로세스의 개수

처리량을 높이려면 CPU burst가 짧은 프로세스에 우선 할당하는 것이 유리하다고 볼 수 있다.

총처리시간(turnaround time) : 'CPU 요청 ~ CPU burst 완료'까지 걸린 시간

준비 큐에서 기다린 시간 + 실제로 CPU를 사용한 시간의 합

대기 시간(waiting time) : 준비 완료 큐에서 대기하면서 보낸 시간의 합

스케줄링 알고리즘은 이 '대기 시간'에만 영향을 준다.

응답 시간(response time) : 프로세스가 CPU 요청 시점부터(준비 큐에 들어온 시점부터)
처음으로 CPU를 얻을 때까지 기다린 시간

응답을 출력하는데 걸리는 시간이 아니라 응답이 시작되는 데까지 걸리는 시간이다. 식당이라고 생각하면 최초 음식이 나오기까지 기다린 시간이라고 보면 된다. 반면, 대기시간은 코스요리라고 한다면 식당에서 순수하게 기다린 시간이라고 보면 된다. 이 응답시간은 대화형 시스템에 적합한 성능 척도이며 사용자 입장에서 가장 중요한 성능 척도라고 할 수 있다.

결국, CPU의 이용률, 처리량은 최대화하면서 총처리 시간, 대기시간, 응답시간은 최소화해야 한다. 시간의 평균을 최적화할 수도 있고 최대값 또는 최소값을 최적화할 수도 있다. 그리고 평균 응답시간의 변동폭을 최소화하는 것도 중요하다.

이제 스케줄링을 하는 다양한 방법을 살펴보자.

## 스케줄링 알고리즘

가장 기본적인 알고리즘은 FCFS 스케줄링 즉 선입 선처리 기법이다.

### FCFS(First Come First Served) 스케줄링

FCFS 스케줄링(선입선처리 스케줄링) : 준비 큐에 도착한 시간 순서대로 CPU를 할당하는 방식

FCFS 스케줄링은 비선점 방식이고 자발적으로 CPU를 반납할 때까지 CPU를 선점하지 않는다.

간단하고 합리적인 스케줄링 방법처럼 보이지만 비효율적인 스케줄링 기법이다. 그 이유는 '평균 대기시간'이 길어질 수 있다는 것이다. 또 그로 인해 'I/O 장치의 이용률'까지 동반 하락하는 문제가 발생한다.

예를 들어 아래와 같은 상황이라고 생각해보자.

![FCFS_scheduling](/images/operating_system/FCFS_scheduling.png)

도착순서만 바꾸어도 평균 대기 시간이 상당히 줄어든 것을 확인할 수 있다. 이것이 FCFS 스케줄링의 단점이다. 이렇게 CPU burst가 짧은 프로세스가 CPU burst가 긴 프로세스보다
나중에 도착해 오랜 시간을 기다려야 하는 현상을 'Convoy effect(호위 효과)'라고 하고 FCFS 스케줄링의 단점이라고 할 수 있다.

결국 이런 단점을 해결하기 위해서는 CPU burst가 짧은 프로세스에 CPU를 먼저 할당해야 하는데 이와 같은 스케줄링 기법이 'SJF 스케줄링'이다.

### SJF(Shortest Job First) 스케줄링

SJF 스케줄링 : CPU burst가 가장 짧은 프로세스에게 제일 먼저 CPU를 할당하는 스케줄링 기법

이 스케줄링 기법은 평균 대기 시간을 가장 짧게 하는 최적의 알고리즘으로 알려져 있다.

SJF 스케줄링은 두 가지 방식으로 나누어진다.

- 선점형 방식 : 새로운 프로세스가 현재 프로세스보다 더 짧은 CPU burst를 가질 때 CPU를 빼앗아 더 짧은 프로세스에게 부여하는 방식(SRFT : Shortest Remaining Time First)
  => 도착 시간이 불규칙한 환경에서 평균 대기시간을 최소화하는 최적의 알고리즘이다.
- 비선점형 방식 : 현재 프로세스가 자신의 CPU burst를 끝내도록 허용하는 방식

예를 들어 아래와 같은 상황이라고 생각하면 평균 대기시간은 각각 다음과 같다.

![SJF_scheduling](/images/operating_system/SJF_scheduling.png)

SJF 스케줄링 알고리즘은 평균 대기시간을 가장 짧게 할 수 있다고 하지만 문제가 있다.
크게 2가지 문제점이 있다. 첫번째 현실적인 문제는 CPU burst time을 미리 알 수 없다는 것이다. 하지만 예측은 가능하다.

예측에는 다음과 같은 방법을 사용한다. 지수 평균(exponential averaging) 방법이라고 말한다.

(n+1) 번째 CPU 버스트의 예측시간 Tn+1은 아래와 같다.

Tn+1 = a _ tn + (1-a) _ Tn

tn 은 n 번째 실제 CPU 버스트 시간을 말하고,
Tn 은 n 번째 CPU 버스트의 예측 시간을 뜻한다.

a 는 0과 1 사이의 값을 가지고 예측에서의 최근 값과 이전 값의 상대적인 가중치를 결정한다.
과거의 CPU 버스트 시간들을 통해 미래의 CPU 버스트 시간을 예측하게 되고 최근 CPU 버스트 시간일수록 오래 전의 CPU 버스트 시간에 비해 가중치를 높이는 방식이다.

위 공식에서 n 대신 n-1을 대입한 식 Tn = a _ tn-1 + (1-a) _ Tn-1 을 Tn 자리에 넣어서 풀고, 다시 n-2을 대입하는 식으로 반복하면 아래와 같은 식을 얻을 수 있다.

Tn+1 = a _ tn + (1-a) _ a _ tn-1 + ... + (1-a)^j _ a \* tn-j + ...

즉, 더 오래된 과거일수록 그 영향력이 적어지도록 반영하는 방식인 것이다.

SJF 스케줄링의 두 번째 문제점은 바로 기아 현상(starvation)이다. CPU burst time이 긴 프로세스가 있는데 CPU burst time이 짧은 프로세스들이 계속적으로 도착한다면 CPU burst time이 더 짧은 프로세스가 우선권을 가지기 때문에 CPU burst time이 상대적으로 긴 프로세스는 계속 밀려나는 문제가 생기는 것이다.

SJF 스케줄링은 CPU burst time을 우선순위의 기준으로 삼은 스케줄링인데 다른 우선순위를 기준으로 스케줄링을 하는 것도 가능하다.

### 우선순위 스케줄링(Priority Scheduling)

우선순위 스케줄링 : 우선순위가 가장 높은 프로세스에게 제일 먼저 CPU를 할당하는 방식

우선순위를 결정하는 방법은 다양할 수 있다. 예를 들어 시간 제한, 메모리 요구, 열린 파일의 수,
평균 입출력 버스트의 평균 등이 우선순위를 결정하는 계산에 사용될 수 있다.

SJF 스케줄링이 우선순위 스케줄링의 일종이기 때문에 우선순위 스케줄링은 SJF 스케줄링처럼 선점형 방식일 수도 있고 비선점형 방식일 수도 있다.

우선순위 스케줄링의 문제점 중 하나는 기아 현상이 발생할 수 있다는 것이다. 우선순위가 높은 프로세스가 계속 도착할 경우 우선순위가 낮은 프로세스는 CPU를 얻지 못한 채 계속 기다려야 하는 상황이 발생할 수 있기 때문이다.

이러한 문제점을 해결하기 위해 사용할 수 있는 방법 중 하나는 노화(aging) 기법이다. 노화기법은 기다리는 시간이 길어지면 우선순위를 조금씩 높여 언젠가는 가장 높은 우선순위가 되어 CPU를 할당받을 수 있게 해주는 기법이다.

다음으로 살펴볼 스케줄링 기법은 현대 시분할 시스템이 기반하고 있는 '라운드 로빈 스케줄링' 기법이다.

### 라운드 로빈 스케줄링(Round-Robin Scheduling)

라운드 로빈 스케줄링 : 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 특정 시간으로 제한되며, 시간이 경과되면 프로세스로부터 CPU를 회수해 준비 큐에 줄 서 있는 다른 프로세스에게 CPU를 할당하는 방식
(한 번에 CPU를 연속적으로 사용할 수 있는 최대 시간을 할당 시간(time quantum)이라고 하고 할당
시간을 넘으면 준비 큐의 제일 뒤에 가서 줄을 서게 된다.)

라운드 로빈 스케줄링은 할당 시간이 경과하면 CPU의 제어권이 넘어가기 때문에 선점형 방식이라고 할 수 있다. 이를 통해 대화형 시스템에서의 빠른 응답 시간을 보장할 수 있다는 장점이 있다.

또한, 준비 큐에 n개의 프로세스가 있고, 시간 할당량이 q라면 각 프로세스는 최대 (n-1) \* q 시간 이상을 기다리지 않는다. 각 프로세스의 대기 시간이 CPU 버스트 시간에 비례하기 때문에 합리적이라고 할 수 있다.

라운드 로빈 스케줄링 알고리즘의 성능은 할당 시간에 상당한 영향을 받는다. 할당시간이 너무 길면, 라운드 로빈 스케줄링은 FCFS 스케줄링과 다름이 없게 되어버린다. 한편 할당시간이 너무 짧으면, CPU를 사용하는 프로세스가 너무 빈번하게 교체되어 문맥 교환의 오버헤드가 커진다.

소요시간(총 처리 시간) 역시 할당 시간의 크기에 좌우된다. 대부분의 프로세스들이 단일 시간 할당량 안에 다음 CPU 버스트를 끝낸다면 평균 총처리 시간은 개선된다. 예를 들어 10시간 단위를 가지는 세 개의 프로세스들이 있고 시간 할당량이 1시간 단위라면 평균 총 처리 시간은 29시간이 된다. 반면, 할당 시간이 10이라면, 평균 총처리 시간은 20으로 줄어든다.

FCFS 스케줄링 알고리즘의 경우 CPU를 먼저 쓰고 나가는 프로세스들의 소요 시간 및 대기 시간이 짧아지는 반면 라운드 로빈 스케줄링에서는 CPU를 조금씩 같이 쓰고 거의 동시에 끝나게 되어 소요 시간 및 대기 시간이 가장 오래 기다린 프로세스에 맞추어지게 되는 것이다.

동일한 CPU 버스트 시간을 가지는 프로세스를 가지는 프로세스들에 대해 라운드 로빈 스케줄링을 적용할 경우 평균 대기 시간 및 평균 소요 기간이 더 길어진다는 것이다. 하지만 일반적으로 프로세스의 CPU 버스트 시간이 균일하지 않고 각자 다른 CPU 버스트와 I/O 버스트를 가지는 경우가 대부분이기 떄문에 CPU 사용량에 비례해 소요 시간이 증가하는 합리적인 스케줄링이라고 볼 수 있다.

이 때까지의 알고리즘은 프로세스들이 CPU를 할당받기 위해 하나의 큐에 서서 대기하는 방식이었는데 앞으로 살펴보는 스케줄링 알고리즘은 여러 개의 큐에 줄을 서서 대기하는 방식이다. 이 중 가장 기본적인 형태는 '멀티 레벨 큐'다.

### 멀티레벨 큐 스케줄링(Multilevel Queue Scheduling)

멀티레벨 큐 스케줄링 : 준비 큐를 여러 개로 분할해서 관리하는 스케줄링 기법

프로세스들을 하나의 준비 큐에 한 줄 세우기를 하는 것이 아니라 여러 개의 준비 큐에 여러 줄로 세우는 기법이다. 성격이 다른 프로세스들을 별도로 관리하고 성격에 맞는 스케줄링을 적용하기 위해 고안된 기법이다.

![multilevel_queue](/images/operating_system/multilevel_queue.png)

예를 들어 대화형 시스템 프로세스들과 일괄 처리 프로세스들로 구분하여 대화형 시스템 프로세스들에 대해서는 응답시간을 위해 라운드 로빈 스케줄링을 적용하고 일괄 처리 프로세스들에 대해서는 선입 선처리 스케줄링을 적용할 수 있다.

멀티레벨 큐 스케줄링에서는 또 다른 스케줄링이 필요한데 바로 준비 큐 자체에 대한 스케줄링이다. 어느 준비 큐에 대해 CPU를 먼저 할당할 것인지를 결정하는 스케줄링이 필요한 것이다.

가장 쉽게 생각할 수 있는 방식은 고정 우선순위 방식이다. 이 방식에서는 큐에 고정적인 우선순위를 부여해 우선순위가 높은 큐를 먼저 서비스하고 우선순위가 낮은 프로세스는 우선순위가 높은 큐가 비어 있을 때에만 서비스하게 된다.

또 다른 방법으로 생각할 수 있는 것은 타임 슬라이스 방식이다. 고정 우선순위 방식의 경우 기아 현상이 발생할 수 있기 때문에 타임 슬라이스 방식을 사용하면 이러한 문제점을 어느 정도 해소할 수 있다. 예를 들어 전체 CPU 시간 중 전위 큐에 대해서는 80%, 후위 큐에 대해서는 20%를 할당해 스케줄링하는 방식을 사용할 수 있다.

이러한 멀티레벨 큐 스케줄링처럼 여러 큐에 줄을 세운다는 측면에서는 멀티 레벨 큐와 동일하지만,
프로세스가 하나의 큐에서 다른 큐로 이동 가능한 스케줄링이 '멀티레벨 피드백 큐 스케줄링'이다.

### 멀티레벨 피드백 큐 스케줄링(Multilevel feedback queue Scheduling)

멀티레벨 피드백 큐 스케줄링은 여러 준비 큐에 줄을 세운다는 측면에서는 멀티레벨 큐와 동일하지만, 프로세스가 하나의 큐에서 다른 큐로 이동 가능하다는 점이 다르다.

예를 들어 우선순위 스케줄링에서의 문제점인 기아 현상을 해결하기 위해 노화 기법을 활용해서 우선순위가 낮은 큐에서 오래 기다렸으면 우선순위가 높은 승격시키는 방식을 고려해볼 수 있는 것이다.

이 때까지의 CPU 스케줄링은 CPU가 하나만 있다고 가정했을 때의 스케줄링이었다. 하지만 CPU가 여러 개라고 하면 더 복잡한 스케줄링 알고리즘이 필요하게 된다.

## 멀티 프로세서 스케줄링(Multi-processor system Scheduling)

멀티 프로세서 스케줄링은 CPU가 여러 개일 때의 스케줄링 기법이다.

만일 여러 개의 CPU가 사용 가능하다면 부하 공유(load sharing)이 가능해진다. 그러므로 멀티 프로세서 스케줄링에서는 CPU별 부하가 적절히 분산되도록 하는 부하 균형(load balancing) 메커니즘이 중요해진다.

이 멀티 프로세서 스케줄링에서는 두 가지 방법을 생각해볼 수 있는데 한 가지는 비대칭형 다중처리 기법이다. 비대칭형 다중처리 기법은 하나의 CPU가 다른 모든 CPU의 스케줄링 및 데이터의 접근을 책임지고 나머지 CPU는 거기에 따라 움직이는 방식이다.

다른 한 가지는 대칭형 다중처리 기법(SMP : symmetric multiprogramming)이다. 이는 프로세서 각각이 독자적으로 스케줄링하는 방식이다. 여러 개의 CPU가 공동 자료구조에 접근하고 갱신하려고 할 수 있기 때문에 비대칭형 다중처리 기법에 비해 신중하게 프로그램되어야 하고 더욱 복잡하다.

이 대칭형 다중처리 기법에서 고려해야 할 이슈가 몇 가지 있다.

1. 처리기 친화성

프로세스가 특정 프로세스에서 실행 중일 때 캐시 메모리에서 어떤 일이 벌어지는지 생각해볼 필요가 있다. CPU가 가장 최근에 접근한 데이터가 그 CPU의 캐시를 채우게 된다. 그런데 이 프로세스가 다른 CPU로 옮겨가게 된다면 첫 번째 CPU의 캐시 메모리 내용은 무효화 되어야 하고 두 번째 캐시의 내용은 다시 채워져야 한다. 이렇게 캐시 메모리의 내용을 무효화하고 다시 채우는 작업은 비용이 많이 드는 작업이기 때문에 대부분의 SMP 시스템에서는 한 CPU에서 다른 CPU로의 이주를 피하고 같은 CPU에서 최대한 처리하려고 한다. 이를 '처리기 친화성'이라고 한다.

2. 부하 균등화

대칭형 다중처리 시스템에서 CPU가 하나 이상이라는 것을 최대한 활용하려면 부하를 모든 CPU에게 균등하게 배분하는 것이 매우 중요하다. 그렇지 않으면 일부 CPU들이 큰 부하를 가지게 되고 일부 CPU는 유휴 상태에 있게 된다.

부하 균등화를 위해서는 push 이주와 pull 방식의 두 가지 방법이 가능하다. push 방식은 상대적으로 과부하 상태의 CPU에서 부하가 적은 CPU로 이동시키는 방법이다. 반면, pull 방식은 유휴 상태의 CPU가 과부하 상태의 CPU에서 프로세스를 가지고 오는 방법이다.

생각해볼 수 있는 것은 부하 균등화의 이익이 처리기 친화성의 이익에 상충된다는 것이다. 같은 CPU에서 실행시키려는 이점은 그 프로세스가 그 CPU의 캐시 메모리에 존재하는 데이터를 활용하는 것이다. 그러나 프로세스를 한 처리기에서 다른 처리기로 pulling 또는 pushing하면 그 이점이 사라진다. 정답은 없지만 불균등 상태가 일정 수준을 넘어설 때만 프로세스를 이주시키는 등의 방법을 고려해볼 수 있다.

3. 대칭적 다중 스레딩(Symmetric Multithreading)

대칭적 다중 스레딩은 동일한 CPU 상에서 여러 개의 논리적인 처리기를 생성하는 것이다. 이런 방식으로 하나의 CPU 안에서도 여러 개의 CPU가 있는 것 같은 관점을 제공한다. 예를 들어 2개의 물리적인 CPU가 있고 각 물리적인 CPU마다 두 개의 논리적인 CPU가 있다면 4개의 CPU를 가지고 있는 시스템이 된다.

대칭적 다중 스레딩은 소프트웨어가 아닌 하드웨어가 제공하는 특성임을 인지하여야 한다. 예를 들어 두 개의 물리적인 CPU가 있다면 두 스레드가 동일한 물리적인 CPU 안의 두 논리적인 CPU가 아니라 각각 다른 물리적인 CPU에서 실행되도록 스케줄해야 한다.

## 스레드 스케줄링(Thread Scheduling)

앞서 살펴본 것처럼 스레드에는 두 가지가 있다.
하나는 사용자 수준 스레드이고 또 하나는 커널 수준 스레드다.

### Local Scheduling

사용자 수준 스레드의 경우 OS에 의해 스케줄링이 결정되는 것이 아니라 그 프로세스에 CPU의 제어권이 할당되면 thread library에 의해 어떤 스레드를 스케줄링할 것인지 결정되고 같은 프로세스 내부의 스레드끼리 CPU를 두고 경쟁한다.

### Global Scheduling

커널 수준 스레드의 경우 일반 프로세스와 마찬가지로 커널의 단기 스케줄러가 어떤 스레드를 스케줄링할 것인지를 결정한다.

## 알고리즘의 평가

특정 시스템을 위한 CPU 스케줄링 알고리즘은 어떻게 선택해야 할까? 첫 번째 문제는 알고리즘을 선택하는 데 사용할 기준을 정의하는 것이다.

ex) 최대 응답시간이 1초라는 제약 조건에서 CPU 이용률을 극대화한다.

일단 선택 기준을 정의되면, 그 기준을 바탕으로 여러 가지 알고리즘을 평가할 수 있다. 알고리즘을 평가하는데 사용할 수 있는 방법을 하나씩 살펴보자.

1. 결정론적 모델링

사전에 정의된 부하에 대해 각 알고리즘의 성능을 평가하는 것이다. 즉, 정적인 입력 집합을 주고 그에 대해 성능을 평가하는 방법이다.

2. 큐잉 모델

결정론적 모델은 정적인 입력 집합이지만 현실에서는 정적인 입력 집합이 주어지지 않고 CPU와 입출력 버스트 분포를 파악하는 등의 방법이 가능하다. 그러므로 큐잉 모델은 이러한 확률 분포를 통해 프로세스들의 도착률과 CPU의 처리율을 입력값을 주면 복잡한 수학적 계산을 통해 각종 성능 지표를 구하는 방법이라고 할 수 있다.

3. 구현(Implementation)

큐잉 모델과 다르게 실제 시스템에 알고리즘을 구현하여 실제 작업에 대해서 성능을 비교하는 방식이다. 문제점은 알고리즘 코드를 작성하고 이를 반영하기 위해 운영체제의 코드를 수정하는 등의 작업을 거쳐야 하는데 생각보다 쉽지 않고 비용이 드는 일이라는 것이다. 또 다른 어려운 점은 알고리즘이 사용되는 환경이 변화한다는 것이다. 예를 들어 새로운 알고리즘을 구현하여 반영하면 사용자들의 반응도 바뀐다는 것이다. 이를 통해 알고리즘의 성능도 달라질 수 있다는 점이다.

4. 모의 실험(Simulation)

모의 실험은 실제 커널의 코드를 수정하는 것이 아니라 특정 알고리즘과 입력이 있을 때 그 입력에 대한 실행을 시뮬레이션해보는 코드를 작성하는 것으로 간단히 이해할 수 있다.
